\relax 
\babel@aux{nil}{}
\@writefile{toc}{\contentsline {section}{\numberline {0.1}Acknowledgement}{iii}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {0.2}Symbols and Notation}{iv}\protected@file@percent }
\citation{de2018machine}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Abstract}{1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{wimschoutensvg}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Some Financial Pre-knowledge}{2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Options}{2}\protected@file@percent }
\newlabel{Options}{{2.1}{2}}
\newlabel{price_vanillas}{{2.1}{2}}
\citation{heston1993closed}
\citation{madan1998variance}
\citation{wimschoutensvg}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}The Black and Scholes Model}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}The Heston and Variance Gamma model}{3}\protected@file@percent }
\citation{GPRbook}
\citation{camillagpr}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Some Mathematical Pre-knowledge}{6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Bayesian Analysis}{6}\protected@file@percent }
\newlabel{Bayesian_analysis1}{{3.1}{6}}
\newlabel{Bayesian_analysis2}{{3.2}{6}}
\citation{GPRbook}
\citation{sejdinovic2012rkhs}
\citation{scholkopf2001generalized}
\newlabel{Bayesian_analysis3}{{3.3}{7}}
\newlabel{Bayesian_analysis4}{{3.4}{7}}
\newlabel{Bayesian_analysis5}{{3.5}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Functional Analysis}{7}\protected@file@percent }
\newlabel{Functional_Analysis}{{3.2}{7}}
\newlabel{Functional_Kernel}{{11}{8}}
\newlabel{Functional_Product}{{5}{8}}
\newlabel{Functional_Product_first_eq}{{3.7}{8}}
\newlabel{Functional_Representer}{{6}{9}}
\newlabel{Functional_RegularizedRisk}{{3.12}{9}}
\newlabel{Functional_mercer}{{7}{10}}
\newlabel{approx_eigenv}{{3.17}{10}}
\newlabel{approx_eigenvector}{{3.19}{11}}
\citation{GPRbook}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Gaussian Process Regression}{12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Bayesian View}{12}\protected@file@percent }
\newlabel{section_bayesian_view}{{4.1}{12}}
\newlabel{GPR_Bayesian_5}{{4.1}{12}}
\newlabel{GPR_Bayesian_1}{{4.2}{12}}
\newlabel{GPR_Bayesian_4}{{4.4}{13}}
\newlabel{GPR_Bayesian_2}{{4.7}{13}}
\citation{GPRbook}
\citation{de2018machine}
\newlabel{GPR_Bayesian_3}{{4.9}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Function Space View}{14}\protected@file@percent }
\newlabel{functionspace}{{4.2}{14}}
\newlabel{condition_gpr}{{4.11}{14}}
\newlabel{function_1_gpr}{{4.12}{14}}
\citation{welling2013kernel}
\citation{GPRbook}
\citation{camillagpr}
\newlabel{Function_Space_final_equation1}{{4.15}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Hyperparameter Selection}{15}\protected@file@percent }
\newlabel{section_hyperparameter_selection}{{4.3}{15}}
\citation{GPRbook}
\citation{de2018machine}
\citation{chen2018priors}
\newlabel{log_marg_llh}{{4.17}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}The Algorithm}{16}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Standard GPR\relax }}{17}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{Standard GPR}{{1}{17}}
\@writefile{toc}{\contentsline {paragraph}{Proof:}{17}\protected@file@percent }
\citation{saatcci2012scalable}
\citation{wilson2015kernel}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Exploiting The Structure}{18}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Kronecker Gaussian Process regression}{18}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces A 2-dimensional rectilinear grid\relax }}{18}\protected@file@percent }
\newlabel{fig:kronecker}{{5.1}{18}}
\newlabel{Kronecker1}{{5.1}{18}}
\citation{saatcci2012scalable}
\citation{riley2006mathematical}
\citation{wilson2014covariance}
\citation{chan1994circulant}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Toeplitz Gaussian Process regression}{19}\protected@file@percent }
\citation{quinonero2005unifying}
\citation{snelson2006sparse}
\citation{GPRbook}
\citation{quinonero2005unifying}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Approximations}{21}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Sparse Gaussian process regression}{21}\protected@file@percent }
\newlabel{integraal}{{6.1}{21}}
\newlabel{approximate_llh}{{6.3}{22}}
\newlabel{sparse1}{{6.7}{22}}
\citation{GPRbook}
\newlabel{prior_DTC}{{6.10}{23}}
\newlabel{sparse_sor}{{6.11}{23}}
\newlabel{pred_SoR}{{6.12}{23}}
\newlabel{llh_dtc}{{6.15}{24}}
\newlabel{dtc}{{6.16}{24}}
\newlabel{sparse2}{{6.18}{24}}
\newlabel{pred_DTC}{{6.19}{24}}
\citation{snelson2006sparse}
\newlabel{sor_and_fic}{{6.26}{26}}
\newlabel{log_marg_ind_input}{{6.28}{26}}
\newlabel{time_compl_evid_approx}{{9}{26}}
\@writefile{toc}{\contentsline {paragraph}{Proof:}{26}\protected@file@percent }
\newlabel{Sparse_efficient_cal}{{6.30}{26}}
\citation{titsias2009variational}
\citation{hensman2013gaussian}
\@writefile{toc}{\contentsline {paragraph}{Proof:}{27}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Variational Gaussian Process Regression}{27}\protected@file@percent }
\newlabel{var_regr}{{6.2}{27}}
\newlabel{variational_start}{{6.33}{27}}
\newlabel{sparse_var_1}{{6.36}{28}}
\newlabel{sparse_var_5}{{6.37}{28}}
\newlabel{lemma_bound1}{{1}{28}}
\newlabel{sparse_var_2}{{6.39}{28}}
\@writefile{toc}{\contentsline {paragraph}{Proof:}{28}\protected@file@percent }
\citation{titsias2009variational}
\newlabel{equation_VFE}{{6.41}{29}}
\newlabel{sparse_var_3}{{6.42}{29}}
\@writefile{toc}{\contentsline {paragraph}{Proof:}{29}\protected@file@percent }
\citation{titsias2009variational}
\citation{GPRbook}
\newlabel{marg_on_u}{{6.44}{30}}
\newlabel{optimal_q}{{6.45}{30}}
\newlabel{mean_predicitive_dtc}{{6.46}{30}}
\citation{bauer2016understanding}
\citation{hensman2013gaussian}
\citation{hensman2013gaussian}
\citation{hensman2013gaussian}
\newlabel{log_marg_ind_input}{{6.48}{31}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Stochastic Variational Gaussian Process Regression}{31}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Requirements for SVI\relax }}{32}\protected@file@percent }
\newlabel{fig:var_1.1}{{6.1}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Standard GPR\relax }}{32}\protected@file@percent }
\newlabel{fig:var_1.2}{{6.2}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Variational GPR\relax }}{32}\protected@file@percent }
\newlabel{fig:var_1.3}{{6.3}{32}}
\newlabel{l2bound}{{6.54}{33}}
\newlabel{variational}{{6.56}{33}}
\newlabel{Stochastvargpr}{{6.58}{34}}
\@writefile{toc}{\contentsline {paragraph}{Proof:}{34}\protected@file@percent }
\citation{hensman2013gaussian}
\newlabel{variational_pred}{{6.65}{36}}
\citation{wilson2015kernel}
\citation{wilson2015thoughts}
\citation{dong2017scalable}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Numerical Based Methods}{37}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Structured Kernel Interpolation}{37}\protected@file@percent }
\newlabel{section_struct_ker_interpol}{{7.1}{37}}
\newlabel{interpolsation_1d}{{7.2}{37}}
\citation{wilson2015kernel}
\newlabel{SKI_theorem}{{12}{38}}
\@writefile{toc}{\contentsline {paragraph}{Proof:}{38}\protected@file@percent }
\newlabel{Function_Space_final_equation1}{{7.6}{38}}
\citation{wilson2015thoughts}
\citation{gardner2018product}
\citation{ubaru2017fast}
\citation{gardner2018product}
\citation{gardner2018product}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Product Kernel Interpolation for Scalable Gaussian Processes}{39}\protected@file@percent }
\newlabel{Product_kernel_interpol_1}{{7.8}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Figure from \cite  {gardner2018product}. Illustration MVMs with the product kernel $K_{X,X}^{1} \circ K_{X,X}^{2}$ \relax }}{40}\protected@file@percent }
\newlabel{fig:MVM}{{7.1}{40}}
\newlabel{lemma_time_complexity_lancos_decomposition}{{3}{40}}
\newlabel{lemma_time_complexity_matrix_mult}{{4}{40}}
\@writefile{toc}{\contentsline {paragraph}{Proof:}{40}\protected@file@percent }
\citation{gardner2018gpytorch}
\newlabel{theorem_multi_prod}{{13}{41}}
\@writefile{toc}{\contentsline {paragraph}{Proof:}{41}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Proof:}{41}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Blackbox Matrix-Matrix Gaussian Process}{41}\protected@file@percent }
\newlabel{section_BBMM}{{7.3}{41}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Modified Preconditioned Conjugate Gradient Method (MBCG)\relax }}{43}\protected@file@percent }
\newlabel{MBCG}{{2}{43}}
\newlabel{equation_trace}{{7.16}{44}}
\newlabel{appendix_stoch_tr_approx}{{7.17}{44}}
\newlabel{equation_bbmm_einde}{{7.18}{44}}
\citation{wang2019exact}
\citation{lalchand2019approximate}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Dessert: Bayesian and Deep Methods}{46}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Fully Bayesian GPR}{{8}{46}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Fully Bayesian GPR}{46}\protected@file@percent }
\citation{modelscomparative}
\citation{murray2010slice}
\newlabel{full_bayesian}{{8.6}{47}}
\newlabel{log_marg_ind_input}{{8.7}{47}}
\citation{hensman2015mcmc}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Bayesian Variational Method}{48}\protected@file@percent }
\newlabel{advanced}{{8.2}{48}}
\citation{murray2010slice}
\citation{hensman2015mcmc}
\citation{nielsen2015neural}
\citation{wilson2016deep}
\citation{wilson2016deep}
\citation{wilson2016deep}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Deep methods for Gaussian processes}{49}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces Figure from \cite  {wilson2016deep}. Deep Kernel Learning also including multidimensional outputs\relax }}{49}\protected@file@percent }
\newlabel{fig:deep_gpr1.1}{{8.1}{49}}
\citation{wilson2016stochastic}
\citation{damianou2013deep}
\citation{damianou2013deep}
\citation{salimbeni2017doubly}
\citation{salimbeni2017doubly}
\citation{kingma2015variational}
\citation{abadi2016tensorflow}
\citation{salvatier2016probabilistic}
\citation{gardner2018gpytorch}
\citation{de2018machine}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Gaussian Process Regression in Finance}{52}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{GPR_in finance}{{9}{52}}
\@writefile{lot}{\contentsline {table}{\numberline {9.1}{\ignorespaces Parameter ranges training and validation vanilla options\relax }}{53}\protected@file@percent }
\newlabel{table_vanilla's}{{9.1}{53}}
\@writefile{lot}{\contentsline {table}{\numberline {9.2}{\ignorespaces Training and predicting vanilla calls using the Heston model\relax }}{55}\protected@file@percent }
\newlabel{Result_Heston_Vanilla_Call}{{9.2}{55}}
\@writefile{lot}{\contentsline {table}{\numberline {9.3}{\ignorespaces Parameter ranges training and validation for DOBP options \relax }}{56}\protected@file@percent }
\newlabel{table_DOBP}{{9.3}{56}}
\@writefile{lot}{\contentsline {table}{\numberline {9.4}{\ignorespaces Training and predicting DOBP options using the Heston model\relax }}{57}\protected@file@percent }
\newlabel{dobp_outcomes}{{9.4}{57}}
\@writefile{lot}{\contentsline {table}{\numberline {9.5}{\ignorespaces Parameter ranges training and validation for American options \relax }}{58}\protected@file@percent }
\newlabel{table_American}{{9.5}{58}}
\@writefile{lot}{\contentsline {table}{\numberline {9.6}{\ignorespaces Training and predicting American put options\relax }}{59}\protected@file@percent }
\newlabel{Result_American}{{9.6}{59}}
\newlabel{fig:bayesian_1}{{\caption@xref {fig:bayesian_1}{ on input line 2179}}{60}}
\newlabel{fig:bayesian_2}{{\caption@xref {fig:bayesian_2}{ on input line 2184}}{60}}
\newlabel{fig:bayesian_3}{{\caption@xref {fig:bayesian_3}{ on input line 2192}}{60}}
\newlabel{fig:bayesian_4}{{\caption@xref {fig:bayesian_4}{ on input line 2197}}{60}}
\newlabel{fig:bayesian_5}{{\caption@xref {fig:bayesian_5}{ on input line 2205}}{60}}
\newlabel{fig:bayesian_6}{{\caption@xref {fig:bayesian_6}{ on input line 2210}}{60}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.1}{\ignorespaces Plots price against strike vanilla calls going full bayesian in het Heston model.\relax }}{60}\protected@file@percent }
\newlabel{fig:bayesian_7}{{9.1}{60}}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Scheme and Conclusion}{61}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sum_conc}{{10}{61}}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Scheme}{61}\protected@file@percent }
\newlabel{summary}{{10.1}{61}}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Conclusion}{62}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces All the models\relax }}{63}\protected@file@percent }
\newlabel{fig:summary}{{10.1}{63}}
\citation{wimschoutensvg}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Appendix}{64}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Brownian motion}{64}\protected@file@percent }
\newlabel{Brownian_Motion}{{11.1}{64}}
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Pricing Derivatives Using Binomial Trees}{64}\protected@file@percent }
\newlabel{appendix_tree}{{11.2}{64}}
\citation{carr1999option}
\@writefile{toc}{\contentsline {section}{\numberline {11.3}The FFT Algorithm}{65}\protected@file@percent }
\newlabel{Fast_Fourrier_transform}{{11.3}{65}}
\newlabel{FFT_1}{{11.5}{65}}
\newlabel{FFT_2}{{11.6}{66}}
\newlabel{FFT_5}{{11.7}{66}}
\newlabel{FFT_3}{{11.8}{66}}
\newlabel{FFT_4}{{11.9}{66}}
\newlabel{FFT_6}{{11.10}{66}}
\citation{palczewski2016numerical}
\citation{GPRbook}
\@writefile{toc}{\contentsline {section}{\numberline {11.4}Pricing derivatives using Monte Carlo Simulations}{67}\protected@file@percent }
\newlabel{derivativesMCS}{{11.4}{67}}
\@writefile{toc}{\contentsline {section}{\numberline {11.5}Bayes Theorem}{67}\protected@file@percent }
\newlabel{BayesTheorem}{{11.16}{67}}
\citation{GPRbook}
\citation{Kuss:06}
\citation{liu1989limited}
\@writefile{toc}{\contentsline {section}{\numberline {11.6}The Matrix Inversion Lemma}{68}\protected@file@percent }
\newlabel{InversionLemma}{{11.6}{68}}
\@writefile{toc}{\contentsline {section}{\numberline {11.7}Gaussian Identities}{68}\protected@file@percent }
\newlabel{Conditioning_of_Gaussians}{{11.7}{68}}
\newlabel{appendix_linearform}{{6}{68}}
\newlabel{appendix_integrals_gaussians}{{9}{68}}
\citation{krishnamoorthy2013matrix}
\citation{saatcci2012scalable}
\@writefile{toc}{\contentsline {section}{\numberline {11.8}L-BFGS}{69}\protected@file@percent }
\newlabel{appendix_Lbfgs}{{11.8}{69}}
\@writefile{toc}{\contentsline {section}{\numberline {11.9}Cholesky decomposition}{69}\protected@file@percent }
\newlabel{Cholesky}{{11.9}{69}}
\@writefile{toc}{\contentsline {section}{\numberline {11.10}The Kronecker product}{69}\protected@file@percent }
\newlabel{Kronecker_product}{{11.10}{69}}
\newlabel{Kronecker_definition}{{16}{69}}
\citation{pptkmeans}
\newlabel{Kronecker1}{{11.25}{70}}
\newlabel{Properties_Kronecker}{{1}{70}}
\@writefile{toc}{\contentsline {section}{\numberline {11.11}K-means}{70}\protected@file@percent }
\newlabel{appendix_kmeans}{{11.11}{70}}
\citation{ambikasaran2014fast}
\citation{blei2017variational}
\citation{yang2017understanding}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces k-means++ initialisation\relax }}{71}\protected@file@percent }
\newlabel{k-means++ initialisation}{{3}{71}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces LLoyd's algorithm\relax }}{71}\protected@file@percent }
\newlabel{LLoyd's algorithm}{{4}{71}}
\@writefile{toc}{\contentsline {section}{\numberline {11.12}Sylvester's Determinant Identity}{71}\protected@file@percent }
\newlabel{Sylvester}{{11.12}{71}}
\@writefile{toc}{\contentsline {section}{\numberline {11.13}The Kullback-Leibler (KL) divergence and Variational Lower bound}{71}\protected@file@percent }
\newlabel{KL}{{11.13}{71}}
\citation{duchi2007derivations}
\citation{bottou2010large}
\citation{blei2017variational}
\@writefile{toc}{\contentsline {paragraph}{Proof:}{72}\protected@file@percent }
\newlabel{KL_gaussian}{{11}{72}}
\citation{hensman2013}
\citation{hensman2013}
\@writefile{toc}{\contentsline {section}{\numberline {11.14}Stochastic Variational Inference and Stochastic Gradient methods}{73}\protected@file@percent }
\newlabel{appendix_var_inf}{{11.14}{73}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.1}{\ignorespaces Figure from \cite  {hensman2013}. Requirements for SVI\relax }}{73}\protected@file@percent }
\newlabel{fig:var_app_1.1}{{11.1}{73}}
\newlabel{gradient_descent}{{11.32}{73}}
\citation{kingma2014adam}
\citation{hoffman2013stochastic}
\newlabel{stoch_gradient_descent}{{11.33}{74}}
\@writefile{toc}{\contentsline {section}{\numberline {11.15}Adam Optimiser}{74}\protected@file@percent }
\newlabel{appendix_adam}{{11.15}{74}}
\@writefile{toc}{\contentsline {section}{\numberline {11.16}The Natural Gradient}{74}\protected@file@percent }
\newlabel{appendix_nat_grad}{{11.16}{74}}
\citation{keys1981cubic}
\citation{babak2009statistical}
\@writefile{toc}{\contentsline {section}{\numberline {11.17}A Short Notion About Interpolation}{75}\protected@file@percent }
\newlabel{appendix_interpolation}{{11.17}{75}}
\newlabel{general_form}{{11.38}{75}}
\citation{gardner2018gpytorch}
\citation{arbenz2012lecture}
\citation{arbenz2012lecture}
\@writefile{toc}{\contentsline {section}{\numberline {11.18}The Lanczos decomposition}{76}\protected@file@percent }
\newlabel{appendix_lanczos_dec}{{11.18}{76}}
\citation{shewchuk1994introduction}
\@writefile{toc}{\contentsline {section}{\numberline {11.19}Conjugate Gradient Method}{77}\protected@file@percent }
\newlabel{appendix_conj_grad}{{11.19}{77}}
\newlabel{quad_eq}{{11.46}{77}}
\newlabel{search_direction}{{11.49}{77}}
\newlabel{gram-schmidt}{{11.50}{77}}
\newlabel{conjugate_grad_3}{{11.52}{78}}
\newlabel{Conj_grad_1}{{11.53}{78}}
\newlabel{Gram_schmidt_2}{{11.54}{78}}
\citation{gardner2018gpytorch}
\citation{shewchuk1994introduction}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces Conjugate Gradient Method\relax }}{79}\protected@file@percent }
\newlabel{c_g_algorithm}{{5}{79}}
\newlabel{appendix_lancos_cg}{{12}{79}}
\citation{shewchuk1994introduction}
\citation{hutchinson1990stochastic}
\@writefile{toc}{\contentsline {section}{\numberline {11.20}Preconditioning}{80}\protected@file@percent }
\newlabel{appendix_preconditioning}{{11.20}{80}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces Preconditioned Conjugate Gradient Method\relax }}{80}\protected@file@percent }
\newlabel{p_c_g_algorithm}{{6}{80}}
\newlabel{pivot_chol}{{18}{80}}
\citation{andrieu2003introduction}
\@writefile{toc}{\contentsline {section}{\numberline {11.21}Stochastic Trace Estimation}{81}\protected@file@percent }
\newlabel{appendix_stoch_trace}{{11.21}{81}}
\newlabel{stoch_trace_1}{{13}{81}}
\newlabel{stoch_trace_2}{{14}{81}}
\newlabel{appendix_stoch_tr_approx}{{11.63}{81}}
\newlabel{appendix_matrix_lemma}{{15}{81}}
\@writefile{toc}{\contentsline {paragraph}{Proof:}{81}\protected@file@percent }
\citation{andrieu2003introduction}
\citation{andrieu2003introduction}
\citation{betancourt2017conceptual}
\citation{fichtner2018tutorial}
\citation{hoffman2014no}
\@writefile{toc}{\contentsline {section}{\numberline {11.22}Maximum a posteriori (Map) estimation}{82}\protected@file@percent }
\newlabel{Appendix_map}{{11.22}{82}}
\newlabel{appendix_mcmc}{{11.22}{82}}
\@writefile{toc}{\contentsline {section}{\numberline {11.23}Markov Chain Monte Carlo Methods}{82}\protected@file@percent }
\newlabel{appendix_mcmc}{{11.23}{82}}
\citation{betancourt2017conceptual}
\citation{betancourt2017conceptual}
\citation{betancourt2017conceptual}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7}{\ignorespaces Metropolis-Hastings (MH)\relax }}{83}\protected@file@percent }
\newlabel{MH_algorithm}{{7}{83}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.2}{\ignorespaces Plot from \cite  {betancourt2017conceptual}. The red band is the typical set. The arrows describe directions aligned with the typical set which guids the sampling algorithm.\relax }}{83}\protected@file@percent }
\newlabel{fig:typ_set1.1}{{11.2}{83}}
\citation{betancourt2017conceptual}
\citation{betancourt2017conceptual}
\citation{betancourt2017conceptual}
\citation{hoffman2014no}
\citation{hoffman2014no}
\citation{betancourt2017conceptual}
\@writefile{lof}{\contentsline {figure}{\numberline {11.3}{\ignorespaces Plot from \cite  {betancourt2017conceptual}. The pink arrows represent the momentum resampling step and the red arrows the trajectories accros these levels with leapfrog\relax }}{85}\protected@file@percent }
\newlabel{fig:level_set1.1}{{11.3}{85}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {8}{\ignorespaces Hamoltonian Monte Carlo (HMC)\relax }}{85}\protected@file@percent }
\newlabel{MH_algorithm}{{8}{85}}
\bibstyle{apalike}
\bibdata{my}
\bibcite{abadi2016tensorflow}{Abadi et~al., 2016}
\bibcite{ambikasaran2014fast}{Ambikasaran et~al., 2014}
\bibcite{andrieu2003introduction}{Andrieu et~al., 2003}
\bibcite{arbenz2012lecture}{Arbenz et~al., 2012}
\bibcite{babak2009statistical}{Babak and Deutsch, 2009}
\bibcite{bauer2016understanding}{Bauer et~al., 2016}
\bibcite{betancourt2017conceptual}{Betancourt, 2017}
\bibcite{blei2017variational}{Blei et~al., 2017}
\bibcite{bottou2010large}{Bottou, 2010}
\bibcite{camillagpr}{Camilla, 2018}
\bibcite{carr1999option}{Carr and Madan, 1999}
\bibcite{chan1994circulant}{Chan et~al., 1994}
\bibcite{chen2018priors}{Chen and Wang, 2018}
\bibcite{damianou2013deep}{Damianou and Lawrence, 2013}
\bibcite{de2018machine}{De~Spiegeleer et~al., 2018}
\bibcite{dong2017scalable}{Dong et~al., 2017}
\bibcite{duchi2007derivations}{Duchi, 2007}
\bibcite{fichtner2018tutorial}{Fichtner et~al., 2018}
\bibcite{gardner2018gpytorch}{Gardner et~al., 2018a}
\bibcite{gardner2018product}{Gardner et~al., 2018b}
\bibcite{pptkmeans}{Gormley, 2017}
\bibcite{hensman2013gaussian}{Hensman et~al., 2013}
\bibcite{hensman2015mcmc}{Hensman et~al., 2015}
\bibcite{heston1993closed}{Heston, 1993}
\bibcite{hoffman2013stochastic}{Hoffman et~al., 2013}
\bibcite{hoffman2014no}{Hoffman and Gelman, 2014}
\bibcite{hutchinson1990stochastic}{Hutchinson, 1990}
\bibcite{keys1981cubic}{Keys, 1981}
\bibcite{kingma2014adam}{Kingma and Ba, 2014}
\bibcite{kingma2015variational}{Kingma et~al., 2015}
\bibcite{krishnamoorthy2013matrix}{Krishnamoorthy and Menon, 2013}
\bibcite{Kuss:06}{Kuss, 2006}
\bibcite{lalchand2019approximate}{Lalchand and Rasmussen, 2019}
\bibcite{liu1989limited}{Liu and Nocedal, 1989}
\bibcite{madan1998variance}{Madan et~al., 1998}
\bibcite{modelscomparative}{Models-GPM, 2013}
\bibcite{murray2010slice}{Murray and Adams, 2010}
\bibcite{nielsen2015neural}{Nielsen, 2015}
\bibcite{palczewski2016numerical}{Palczewski, 2016}
\bibcite{quinonero2005unifying}{Qui{\~n}onero-Candela and Rasmussen, 2005}
\bibcite{GPRbook}{Rasmussen and Williams, 2006}
\bibcite{riley2006mathematical}{Riley et~al., 2006}
\bibcite{saatcci2012scalable}{Saat{\c {c}}i, 2012}
\bibcite{salimbeni2017doubly}{Salimbeni and Deisenroth, 2017}
\bibcite{salvatier2016probabilistic}{Salvatier et~al., 2016}
\bibcite{scholkopf2001generalized}{Sch{\"o}lkopf et~al., 2001}
\bibcite{wimschoutensvg}{Schoutens, 2008}
\bibcite{sejdinovic2012rkhs}{Sejdinovic and Gretton, 2012}
\bibcite{shewchuk1994introduction}{Shewchuk et~al., 1994}
\bibcite{snelson2006sparse}{Snelson and Ghahramani, 2006}
\bibcite{titsias2009variational}{Titsias, 2009}
\bibcite{ubaru2017fast}{Ubaru et~al., 2017}
\bibcite{wang2019exact}{Wang et~al., 2019}
\bibcite{welling2013kernel}{Welling, 2013}
\bibcite{wilson2015kernel}{Wilson and Nickisch, 2015}
\bibcite{wilson2014covariance}{Wilson, 2014}
\bibcite{wilson2015thoughts}{Wilson et~al., 2015}
\bibcite{wilson2016deep}{Wilson et~al., 2016a}
\bibcite{wilson2016stochastic}{Wilson et~al., 2016b}
\bibcite{yang2017understanding}{Yang, 2017}
